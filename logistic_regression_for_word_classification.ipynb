{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "dJomRL1CCwt3"
      },
      "outputs": [],
      "source": [
        "import nltk                                # Python library for NLP\n",
        "from nltk.corpus import twitter_samples    # sample Twitter dataset from NLTK\n",
        "import matplotlib.pyplot as plt            # library for visualization\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "H5NHPWZIU57C"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package twitter_samples to\n",
            "[nltk_data]     C:\\Users\\8086f\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Unzipping corpora\\twitter_samples.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('twitter_samples')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-3hnIIZonuz",
        "outputId": "1bea1cfa-7a76-4632-a343-a7c95fb57027"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\8086f\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "_f9dLOfMDF4c"
      },
      "outputs": [],
      "source": [
        "# select the set of positive and negative tweets\n",
        "all_positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
        "all_negative_tweets = twitter_samples.strings('negative_tweets.json')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5gC3jkzDSNf",
        "outputId": "acd7673b-5bdd-43d5-c24c-c754d7a123f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5000\n",
            "5000\n"
          ]
        }
      ],
      "source": [
        "print(len(all_positive_tweets))\n",
        "print(len(all_negative_tweets))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t8aVtPcLDcw0",
        "outputId": "decec224-19b9-4553-e6eb-43605efeaee8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "My beautiful sunflowers on a sunny Friday morning off :) #sunflowers #favourites #happy #Friday offâ€¦ https://t.co/3tfYom0N1i\n"
          ]
        }
      ],
      "source": [
        "# Our selected sample. Complex enough to exemplify each step\n",
        "tweet = all_positive_tweets[2277]\n",
        "print(tweet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BPChFwTnVY2E",
        "outputId": "b4937aa1-4f33-427d-870f-421d48e62d75"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\8086f\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# download the stopwords from NLTK\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "GOMH4C_JVbjh"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import string\n",
        "from nltk.stem import PorterStemmer\n",
        "ps=PorterStemmer()\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JP95l7v5Vvma",
        "outputId": "958ccea3-25e6-4d42-8510-a954e5130dc5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "stopwords=nltk.corpus.stopwords.words('english')\n",
        "stopwords[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "6o6XFecCWPAU"
      },
      "outputs": [],
      "source": [
        "def clean_text(text):\n",
        "  stopwords=nltk.corpus.stopwords.words('english')\n",
        "  ps = PorterStemmer()\n",
        "  text=re.sub(r'[^A-Z a-z]','',text)\n",
        "  text=re.sub(r'^# @ _ ',' ',text)\n",
        "  text=text.lower()\n",
        "  text=text.split()\n",
        "  text=[ps.stem(word) for word in text if word not in stopwords]\n",
        "  text=\" \".join(text)\n",
        "  return text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4glxOh9XYE-X",
        "outputId": "6d3fe877-eb6a-42c8-9d17-df8755cf4bee"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['#FollowFriday @France_Inte @PKuchly57 @Milipol_Paris for being top engaged members in my community this week :)',\n",
              " '@Lamb2ja Hey James! How odd :/ Please call our Contact Centre on 02392441234 and we will be able to assist you :) Many thanks!',\n",
              " '@DespiteOfficial we had a listen last night :) As You Bleed is an amazing track. When are you in Scotland?!',\n",
              " '@97sides CONGRATS :)',\n",
              " 'yeaaaah yippppy!!!  my accnt verified rqst has succeed got a blue tick mark on my fb profile :) in 15 days']"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "all_positive_tweets[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "VtJIyejfXpFN",
        "outputId": "ab3f3c6d-4ee7-46ca-a73f-12b00344682f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'followfriday franceint pkuchli milipolpari top engag member commun week'"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clean_text(all_positive_tweets[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "_HPnYmBAoPjI"
      },
      "outputs": [],
      "source": [
        "for i in range(len(all_positive_tweets)):\n",
        "  all_positive_tweets[i]=clean_text(all_positive_tweets[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "oNtxb3UXpQZF"
      },
      "outputs": [],
      "source": [
        "for i in range(len(all_negative_tweets)):\n",
        "  all_negative_tweets[i]=clean_text(all_negative_tweets[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ib5MdaL6EmNv",
        "outputId": "31105611-7402-4770-d9b8-adbd7c5bca52"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['followfriday franceint pkuchli milipolpari top engag member commun week',\n",
              " 'lambja hey jame odd pleas call contact centr abl assist mani thank',\n",
              " 'despiteoffici listen last night bleed amaz track scotland',\n",
              " 'side congrat',\n",
              " 'yeaaaah yippppi accnt verifi rqst succeed got blue tick mark fb profil day']"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tweeTtok=all_positive_tweets+all_negative_tweets\n",
        "\n",
        "tweeTtok[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5a0iwbBnF-y"
      },
      "source": [
        "## Tokenize the string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "De_OTgqpnFgR"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "def process_tweet(tweets):\n",
        "  tokenized_tweets = []  # Initialize an empty list to store tokenized tweets\n",
        "  for tweet in tweets:\n",
        "      tokenized_words = word_tokenize(tweet)\n",
        "      tokenized_tweets.append(tokenized_words)\n",
        "  return tokenized_tweets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZCGugMrtciY",
        "outputId": "e8810be4-609a-4f9a-954c-557da17bd8fc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['M']"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tweeTtok=process_tweet(tweet)\n",
        "tweeTtok[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "GqtbYwNor7v4"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "labels = np.append(np.ones((len(all_positive_tweets))), np.zeros((len(all_negative_tweets))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EucLOfLZsEjl",
        "outputId": "943c203b-1652-4a65-c363-5af91cfa95eb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10000,)"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "labels.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "OvQ6KqKhtRg_"
      },
      "outputs": [],
      "source": [
        "def build_freqs(tweeTtok, ys):\n",
        "    \"\"\"Build frequencies.\n",
        "    Input:\n",
        "        tweeTtok: a list of tweets\n",
        "        ys: an m x 1 array with the sentiment label of each tweet\n",
        "            (either 0 or 1)\n",
        "    Output:\n",
        "        freqs: a dictionary mapping each (word, sentiment) pair to its\n",
        "        frequency\n",
        "    \"\"\"\n",
        "    # Convert np array to list since zip needs an iterable.\n",
        "    # The squeeze is necessary or the list ends up with one element.\n",
        "    # Also note that this is just a NOP if ys is already a list.\n",
        "    yslist = np.squeeze(ys).tolist()\n",
        "\n",
        "    # Start with an empty dictionary and populate it by looping over all tweets\n",
        "    freqs = {}\n",
        "    for y, tweet in zip(yslist, tweeTtok):\n",
        "        for word in process_tweet(tweet):\n",
        "            if isinstance(word, list):\n",
        "                for w in word:\n",
        "                    pair = (w, y)\n",
        "                    if pair in freqs:\n",
        "                        freqs[pair] += 1\n",
        "                    else:\n",
        "                        freqs[pair] = 1\n",
        "            else:\n",
        "                pair = (word, y)\n",
        "                if pair in freqs:\n",
        "                    freqs[pair] += 1\n",
        "                else:\n",
        "                    freqs[pair] = 1\n",
        "    return freqs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qxgR6ZHagWwb"
      },
      "outputs": [],
      "source": [
        "freqs = build_freqs(tweeTtok, labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1xFSX8JlMveL",
        "outputId": "cf124823-e52f-4c2d-856c-83fbb42d67e7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-jbsWL2QSLx",
        "outputId": "1c6537f3-9db6-4c90-8386-45788ba38ce8"
      },
      "outputs": [],
      "source": [
        "# check the output\n",
        "print(\"type(freqs) = \" + str(type(freqs)))\n",
        "print(\"len(freqs) = \" + str(len(freqs.keys())))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "KPzSsVKiRSgj"
      },
      "outputs": [],
      "source": [
        "test_pos = all_positive_tweets[4000:]\n",
        "train_pos = all_positive_tweets[:4000]\n",
        "test_neg = all_negative_tweets[4000:]\n",
        "train_neg = all_negative_tweets[:4000]\n",
        "\n",
        "train_x = train_pos + train_neg\n",
        "test_x = test_pos + test_neg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "ypMLpo_xRb9M"
      },
      "outputs": [],
      "source": [
        "# combine positive and negative labels\n",
        "train_y = np.append(np.ones((len(train_pos), 1)), np.zeros((len(train_neg), 1)), axis=0)\n",
        "test_y = np.append(np.ones((len(test_pos), 1)), np.zeros((len(test_neg), 1)), axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbdjOFoxRhay",
        "outputId": "01d2e636-af3c-4e52-98f2-610adce7e89b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_y.shape = (8000, 1)\n",
            "test_y.shape = (2000, 1)\n"
          ]
        }
      ],
      "source": [
        "print(\"train_y.shape = \" + str(train_y.shape))\n",
        "print(\"test_y.shape = \" + str(test_y.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "WfaBMn6_SVq-"
      },
      "outputs": [],
      "source": [
        "train_x=process_tweet(train_x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GIIcl---S4KI",
        "outputId": "c034750f-2ace-4745-9a26-c67ea300a81b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['followfriday',\n",
              " 'franceint',\n",
              " 'pkuchli',\n",
              " 'milipolpari',\n",
              " 'top',\n",
              " 'engag',\n",
              " 'member',\n",
              " 'commun',\n",
              " 'week']"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_x[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y1LulCqIRkSH",
        "outputId": "44dd269d-9559-4af1-ee52-c7323ba02c13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('followfriday', 1.0) 23\n",
            "type(freqs) = <class 'dict'>\n",
            "len(freqs) = 17865\n"
          ]
        }
      ],
      "source": [
        "freqs = build_freqs(train_x, train_y)\n",
        "#just print a value from dictionary\n",
        "first_key = next(iter(freqs))\n",
        "print(first_key, freqs[first_key])\n",
        "# check the output\n",
        "print(\"type(freqs) = \" + str(type(freqs)))\n",
        "print(\"len(freqs) = \" + str(len(freqs.keys())))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "CukZ3-H_l_Az"
      },
      "outputs": [],
      "source": [
        "# UNQ_C1 GRADED FUNCTION: sigmoid\n",
        "def sigmoid(z):\n",
        "    '''\n",
        "    Input:\n",
        "        z: is the input (can be a scalar or an array)\n",
        "    Output:\n",
        "        h: the sigmoid of z\n",
        "    '''\n",
        "\n",
        "    # calculate the sigmoid of z\n",
        "    h = 1/(1+np.exp(-z))\n",
        "\n",
        "    return h"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "BN56Ry4tOkQp"
      },
      "outputs": [],
      "source": [
        "def gradientDescent(x, y, theta, alpha, num_iters):\n",
        "    '''\n",
        "    Input:\n",
        "        x: matrix of features which is (m,n+1)\n",
        "        y: corresponding labels of the input matrix x, dimensions (m,1)\n",
        "        theta: weight vector of dimension (n+1,1)\n",
        "        alpha: learning rate\n",
        "        num_iters: number of iterations you want to train your model for\n",
        "    Output:\n",
        "        J: the final cost\n",
        "        theta: your final weight vector\n",
        "    Hint: you might want to print the cost to make sure that it is going down.\n",
        "    '''\n",
        "    ### START CODE HERE ###\n",
        "    # get 'm', the number of rows in matrix x\n",
        "    m = x.shape[0]\n",
        "\n",
        "    for i in range(0, num_iters):\n",
        "\n",
        "        # get z, the dot product of x and theta\n",
        "        z = np.dot(x,theta)\n",
        "\n",
        "        # get the sigmoid of z\n",
        "        h = sigmoid(z)\n",
        "\n",
        "        # calculate the cost function\n",
        "        J = (-1/m)*(np.matmul(np.transpose(y),np.log(h)) + np.matmul(np.transpose(1-y),np.log(1-h)))\n",
        "\n",
        "        # update the weights theta\n",
        "        theta = theta - (alpha/m)*np.dot(np.transpose(x),(h-y))\n",
        "\n",
        "    ### END CODE HERE ###\n",
        "    J = float(J)\n",
        "    return J, theta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "vGdf0GdaOmce"
      },
      "outputs": [],
      "source": [
        "def extract_features(tweet, freqs, process_tweet=process_tweet):\n",
        "    '''\n",
        "    Input:\n",
        "        tweet: a list of words for one tweet\n",
        "        freqs: a dictionary corresponding to the frequencies of each tuple (word, label)\n",
        "    Output:\n",
        "        x: a feature vector of dimension (1,3)\n",
        "    '''\n",
        "\n",
        "    # 3 elements in the form of a 1 x 3 vector\n",
        "    x = np.zeros((1, 3))\n",
        "\n",
        "    #bias term is set to 1\n",
        "    x[0,0] = 1\n",
        "\n",
        "    ### START CODE HERE ###\n",
        "\n",
        "    # loop through each word in the list of words\n",
        "    for word in tweet:\n",
        "\n",
        "        if (word, 1.0) in freqs.keys() :\n",
        "        # increment the word count for the positive label 1\n",
        "            x[0,1] += freqs[(word, 1.0)]\n",
        "        if (word, 0.0) in freqs.keys() :\n",
        "        # increment the word count for the negative label 0\n",
        "            x[0,2] += freqs[(word, 0.0)]\n",
        "\n",
        "    ### END CODE HERE ###\n",
        "    assert(x.shape == (1, 3))\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xpGIsEY4PeUN",
        "outputId": "52d72456-aa84-45f5-c987-744014199e5d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[  1., 174.,  60.]])"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "extract_features(train_x[0], freqs=freqs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJr1L9ThT_1_",
        "outputId": "ebe19d69-84cf-40dd-c97f-e514b1785940"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 1. 65. 78.]]\n"
          ]
        }
      ],
      "source": [
        "tmp2 = extract_features('blorb bleeeeb bloooob', freqs)\n",
        "print(tmp2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PixhE5uzUDlZ",
        "outputId": "fe1eeb84-0eb2-4a9d-a500-7dbc0a5e45fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 1.  7. 21.]]\n"
          ]
        }
      ],
      "source": [
        "tmp2 = extract_features('hi this is fijaz', freqs)\n",
        "print(tmp2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "V7_L5cSaVRM_"
      },
      "outputs": [],
      "source": [
        "\n",
        "# collect the features 'x' and stack them into a matrix 'X'\n",
        "X = np.zeros((len(train_x), 3))\n",
        "for i in range(len(train_x)):\n",
        "    X[i, :]= extract_features(train_x[i], freqs)\n",
        "\n",
        "# training labels corresponding to X\n",
        "Y = train_y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DKAkaYnDVUky",
        "outputId": "60dfaf72-3153-4ff6-88f7-85305e29886b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The cost after training is 0.69123464.\n",
            "The resulting vector of weights is [-0.0, 4.949e-05, -2.052e-05].\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\8086f\\AppData\\Local\\Temp\\ipykernel_2288\\124738098.py:33: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  J = float(J)\n"
          ]
        }
      ],
      "source": [
        "J, theta = gradientDescent(X, Y, np.zeros((3, 1)), 1e-9, 1500)\n",
        "print(f\"The cost after training is {J:.8f}.\")\n",
        "print(f\"The resulting vector of weights is {[round(t, 8) for t in np.squeeze(theta)]}.\" )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "Y4wpp_OKVn9A"
      },
      "outputs": [],
      "source": [
        "def predict_tweet(tweet, freqs, theta):\n",
        "    '''\n",
        "    Input:\n",
        "        tweet: a string\n",
        "        freqs: a dictionary corresponding to the frequencies of each tuple (word, label)\n",
        "        theta: (3,1) vector of weights\n",
        "    Output:\n",
        "        y_pred: the probability of a tweet being positive or negative\n",
        "    '''\n",
        "    ### START CODE HERE ###\n",
        "\n",
        "    # extract the features of the tweet and store it into x\n",
        "    x = extract_features(tweet, freqs)\n",
        "\n",
        "    # make the prediction using x and theta\n",
        "    y_pred = sigmoid(np.dot(x,theta))\n",
        "\n",
        "    ### END CODE HERE ###\n",
        "\n",
        "    return y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w8cAaDACVsES",
        "outputId": "365757d3-83b8-489f-be80-270f3a9a09cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "I am happy -> 0.502489\n",
            "I am bad -> 0.500021\n",
            "this movie should have been great. -> 0.502135\n",
            "great -> 0.500159\n",
            "great great -> 0.500319\n",
            "great great great -> 0.500478\n",
            "great great great great -> 0.500637\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\8086f\\AppData\\Local\\Temp\\ipykernel_2288\\2209103747.py:3: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  print( '%s -> %f' % (tweet, predict_tweet(tweet, freqs, theta)))\n"
          ]
        }
      ],
      "source": [
        "# Run this cell to test your function\n",
        "for tweet in ['I am happy', 'I am bad', 'this movie should have been great.', 'great', 'great great', 'great great great', 'great great great great']:\n",
        "    print( '%s -> %f' % (tweet, predict_tweet(tweet, freqs, theta)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DUd0I9h5Vw7p",
        "outputId": "41268cb6-8cd4-4dd7-9528-92cd5fa56c3b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.50025928]])"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "my_tweet = 'I am learning :)'\n",
        "predict_tweet(my_tweet, freqs, theta)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "l7CZUh2IV3Dq"
      },
      "outputs": [],
      "source": [
        "# UNQ_C5 GRADED FUNCTION: test_logistic_regression\n",
        "def test_logistic_regression(test_x, test_y, freqs, theta, predict_tweet=predict_tweet):\n",
        "    \"\"\"\n",
        "    Input:\n",
        "        test_x: a list of tweets\n",
        "        test_y: (m, 1) vector with the corresponding labels for the list of tweets\n",
        "        freqs: a dictionary with the frequency of each pair (or tuple)\n",
        "        theta: weight vector of dimension (3, 1)\n",
        "    Output:\n",
        "        accuracy: (# of tweets classified correctly) / (total # of tweets)\n",
        "    \"\"\"\n",
        "\n",
        "    ### START CODE HERE ###\n",
        "\n",
        "    # the list for storing predictions\n",
        "    y_hat = []\n",
        "\n",
        "    for tweet in test_x:\n",
        "        # get the label prediction for the tweet\n",
        "        y_pred = predict_tweet(tweet, freqs, theta)\n",
        "\n",
        "        if y_pred > 0.5:\n",
        "            # append 1.0 to the list\n",
        "            y_hat.append(1.0)\n",
        "        else:\n",
        "            # append 0 to the list\n",
        "            y_hat.append(0.0)\n",
        "\n",
        "    # With the above implementation, y_hat is a list, but test_y is (m,1) array\n",
        "    # convert both to one-dimensional arrays in order to compare them using the '==' operator\n",
        "\n",
        "    accuracy = 0\n",
        "\n",
        "    for i in range(test_y.shape[0]):\n",
        "        if test_y[i]==y_hat[i]:\n",
        "            accuracy+=1\n",
        "\n",
        "    accuracy=np.float64(accuracy/test_y.shape[0])\n",
        "\n",
        "    ### END CODE HERE ###\n",
        "\n",
        "    return accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vk14va-oV6Df",
        "outputId": "904cae04-acef-4bfc-ff6a-80a735e83d75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic regression model's accuracy = 0.5040\n"
          ]
        }
      ],
      "source": [
        "tmp_accuracy = test_logistic_regression(test_x, test_y, freqs, theta)\n",
        "print(f\"Logistic regression model's accuracy = {tmp_accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j4dqzgumWOgS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZLh420EcWI00",
        "outputId": "49bd2f40-20a7-4be5-b606-71a3d9d20346"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['I', 'won', '!']\n",
            "[[0.50010083]]\n",
            "Positive sentiment\n"
          ]
        }
      ],
      "source": [
        "# Feel free to change the tweet below\n",
        "my_tweet = 'I won!'\n",
        "def process_tweet(my_tweet):\n",
        "  return word_tokenize(my_tweet)\n",
        "print(process_tweet(my_tweet))\n",
        "y_hat = predict_tweet(my_tweet, freqs, theta)\n",
        "print(y_hat)\n",
        "if y_hat > 0.5:\n",
        "    print('Positive sentiment')\n",
        "else:\n",
        "    print('Negative sentiment')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

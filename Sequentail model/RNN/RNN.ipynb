{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vhqzdm_w5-Do",
        "outputId": "a0ff9240-23c2-401d-f29d-ebd538703b58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://homl.info/shakespeare\n",
            "1115394/1115394 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "shakespeare_url = \"https://homl.info/shakespeare\"  # shortcut URL\n",
        "filepath = tf.keras.utils.get_file(\"shakespeare.txt\", shakespeare_url)\n",
        "with open(filepath) as f:\n",
        "    shakespeare_text = f.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lijNCe565-Dp",
        "outputId": "0be5c5d3-1f49-4ac0-bb9a-9c44ffd0560f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You\n"
          ]
        }
      ],
      "source": [
        "print(shakespeare_text[:100])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "-P5KcQcH5-Dq"
      },
      "outputs": [],
      "source": [
        "text_vec_layer = tf.keras.layers.TextVectorization(split=\"character\",\n",
        "                                                   standardize=\"lower\")\n",
        "text_vec_layer.adapt([shakespeare_text])\n",
        "encoded = text_vec_layer([shakespeare_text])[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6HsJbK9U5-Dq",
        "outputId": "3870741b-fa54-47cd-893d-86e465ad2c46"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1115394,), dtype=int64, numpy=array([21,  7, 10, ..., 22, 28, 12])>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "encoded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "108dWOGb5-Dq",
        "outputId": "87bc0682-99fa-4698-b160-73be193f0e8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " number of distinct chars 39\n",
            "total number of chars =1115394\n"
          ]
        }
      ],
      "source": [
        "encoded-=2\n",
        "n_tokens= text_vec_layer.vocabulary_size()-2\n",
        "dataset_size=len(encoded)\n",
        "print(f\" number of distinct chars {n_tokens}\")\n",
        "print(f\"total number of chars ={dataset_size}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "oxiAiVWA5-Dr"
      },
      "outputs": [],
      "source": [
        "def to_dataset(sequence, length, shuffle=False, seed=None, batch_size=32):\n",
        "    ds = tf.data.Dataset.from_tensor_slices(sequence)\n",
        "    ds = ds.window(length + 1, shift=1, drop_remainder=True)\n",
        "    ds = ds.flat_map(lambda window: window.batch(length + 1))\n",
        "    if shuffle:\n",
        "        ds = ds.shuffle(buffer_size=100_000, seed=seed)\n",
        "    ds = ds.batch(batch_size)\n",
        "\n",
        "    def split_input_target(window):\n",
        "        window = tf.expand_dims(window, axis=-1) if len(window.shape) == 1 else window\n",
        "        return window[:, :-1], window[:, 1:]\n",
        "\n",
        "    return ds.map(split_input_target).prefetch(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "msASsOdw5-Dr",
        "outputId": "f0711f72-2459-4bfb-d76f-f8fb6b000999"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32, 100) (32, 100)\n"
          ]
        }
      ],
      "source": [
        "length = 100\n",
        "tf.random.set_seed(42)\n",
        "train_set = to_dataset(encoded[:1_000_000], length=length, shuffle=True, seed=42)\n",
        "valid_set = to_dataset(encoded[1_000_000:1_060_000], length=length)\n",
        "test_set = to_dataset(encoded[1_060_000:], length=length)\n",
        "\n",
        "for input_seq, target_seq in train_set.take(1):\n",
        "    print(input_seq.shape, target_seq.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yOE0CqNV5-Dr",
        "outputId": "b0121c11-ed4d-4269-9bfe-d236679ea2e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "31247/31247 [==============================] - 398s 12ms/step - loss: 1.4027 - accuracy: 0.5705 - val_loss: 1.6007 - val_accuracy: 0.5322\n",
            "Epoch 2/10\n",
            "31247/31247 [==============================] - 403s 12ms/step - loss: 1.2987 - accuracy: 0.5952 - val_loss: 1.5812 - val_accuracy: 0.5408\n",
            "Epoch 3/10\n",
            "31247/31247 [==============================] - 413s 13ms/step - loss: 1.2789 - accuracy: 0.5998 - val_loss: 1.5650 - val_accuracy: 0.5436\n",
            "Epoch 4/10\n",
            "31247/31247 [==============================] - 427s 13ms/step - loss: 1.2687 - accuracy: 0.6021 - val_loss: 1.5649 - val_accuracy: 0.5431\n",
            "Epoch 5/10\n",
            "31247/31247 [==============================] - 406s 12ms/step - loss: 1.2628 - accuracy: 0.6035 - val_loss: 1.5643 - val_accuracy: 0.5455\n",
            "Epoch 6/10\n",
            "31247/31247 [==============================] - 403s 12ms/step - loss: 1.2575 - accuracy: 0.6045 - val_loss: 1.5640 - val_accuracy: 0.5454\n",
            "Epoch 7/10\n",
            "31247/31247 [==============================] - 399s 12ms/step - loss: 1.2533 - accuracy: 0.6056 - val_loss: 1.5666 - val_accuracy: 0.5450\n",
            "Epoch 8/10\n",
            "31247/31247 [==============================] - 406s 12ms/step - loss: 1.2510 - accuracy: 0.6060 - val_loss: 1.5597 - val_accuracy: 0.5454\n",
            "Epoch 9/10\n",
            "31247/31247 [==============================] - 422s 13ms/step - loss: 1.2485 - accuracy: 0.6067 - val_loss: 1.5613 - val_accuracy: 0.5470\n",
            "Epoch 10/10\n",
            "31247/31247 [==============================] - 404s 12ms/step - loss: 1.2467 - accuracy: 0.6070 - val_loss: 1.5576 - val_accuracy: 0.5475\n"
          ]
        }
      ],
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(input_dim=n_tokens, output_dim=16),\n",
        "    tf.keras.layers.GRU(128, return_sequences=True),\n",
        "    tf.keras.layers.Dense(n_tokens, activation=\"softmax\")\n",
        " ])\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model_ckpt = tf.keras.callbacks.ModelCheckpoint(\n",
        "    \"my_shakespeare_model.keras\", monitor=\"val_accuracy\", save_best_only=True)\n",
        "history = model.fit(train_set, validation_data=valid_set, epochs=10,\n",
        "                    callbacks=[model_ckpt])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "iq1N_XL25-Ds"
      },
      "outputs": [],
      "source": [
        " shakespeare_model = tf.keras.Sequential([\n",
        " text_vec_layer,\n",
        " tf.keras.layers.Lambda(lambda X: X - 2),  # no <PAD> or <UNK> tokens\n",
        " model\n",
        " ])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "pickle.dump(model,open(\"model.keras\",\"wb\"))"
      ],
      "metadata": {
        "id": "4RGq_73J-76Q"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf_loaded = pickle.load(open(\"model.keras\",\"rb\"))"
      ],
      "metadata": {
        "id": "_dhjhvPKLQda"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_proba = shakespeare_model.predict([\"To be or not to b\"])[0, -1]\n",
        "y_pred = tf.argmax(y_proba)\n",
        "text_vec_layer.get_vocabulary()[y_pred + 2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "AyJAtsE1LSy6",
        "outputId": "70797331-3a3b-40d8-ac04-e88ad5396bdc"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'e'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " def next_char(text, temperature=1):\n",
        "        y_proba = shakespeare_model.predict([text])[0, -1:]\n",
        "        rescaled_logits = tf.math.log(y_proba) / temperature\n",
        "        char_id = tf.random.categorical(rescaled_logits, num_samples=1)[0, 0]\n",
        "        return text_vec_layer.get_vocabulary()[char_id + 2]"
      ],
      "metadata": {
        "id": "2NjCkdMDLdgg"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extend_text(text, n_chars=50, temperature=1):\n",
        "    for _ in range(n_chars):\n",
        "        text += next_char(text, temperature)\n",
        "    return text"
      ],
      "metadata": {
        "id": "AbpkkTxXLjUS"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "print(extend_text(\"To be or not to be\", temperature=0.01))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrwJh1_aLmDh",
        "outputId": "eee370d2-d256-452c-f1b1-ec4e53266535"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 341ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "1/1 [==============================] - 0s 88ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 184ms/step\n",
            "1/1 [==============================] - 0s 90ms/step\n",
            "1/1 [==============================] - 0s 77ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 83ms/step\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "1/1 [==============================] - 0s 188ms/step\n",
            "1/1 [==============================] - 0s 171ms/step\n",
            "1/1 [==============================] - 0s 156ms/step\n",
            "1/1 [==============================] - 0s 184ms/step\n",
            "1/1 [==============================] - 0s 125ms/step\n",
            "1/1 [==============================] - 0s 69ms/step\n",
            "1/1 [==============================] - 0s 126ms/step\n",
            "1/1 [==============================] - 0s 159ms/step\n",
            "1/1 [==============================] - 0s 223ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 102ms/step\n",
            "1/1 [==============================] - 0s 133ms/step\n",
            "1/1 [==============================] - 0s 133ms/step\n",
            "1/1 [==============================] - 0s 70ms/step\n",
            "1/1 [==============================] - 0s 107ms/step\n",
            "1/1 [==============================] - 0s 107ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 120ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 95ms/step\n",
            "1/1 [==============================] - 0s 118ms/step\n",
            "1/1 [==============================] - 0s 78ms/step\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "1/1 [==============================] - 0s 126ms/step\n",
            "To be or not to be so come to see\n",
            "the state will be a sister, and so\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "print(extend_text(\"To be or not to be\", temperature=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Itr4wUcELpHs",
        "outputId": "459adccd-c765-4d44-dd2f-5dcfdf2a2d11"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 306ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "To be or not to be to did,\n",
            "die too, as it vincentic beaughia,\n",
            "your m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "print(extend_text(\"To be or not to be\", temperature=1.5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BcndHO2LLw5a",
        "outputId": "2ee0b4c6-4c9c-4da1-d283-445d885a7a85"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 145ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "To be or not to be two\n",
            "chairs had erracts vice want beloved wonder's\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aD4gBUw7L4sR"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}